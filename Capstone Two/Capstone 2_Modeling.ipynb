{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ajdou\\\\Desktop\\\\Springboard\\\\assignments\\\\Capstone Project 2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in dataset\n",
    "df = pd.read_csv('data\\\\model_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_wc</th>\n",
       "      <th>title_wc</th>\n",
       "      <th>av_word_len_text</th>\n",
       "      <th>av_word_len_title</th>\n",
       "      <th>upper_text_wc</th>\n",
       "      <th>upper_title_wc</th>\n",
       "      <th>numerics_text</th>\n",
       "      <th>numerics_title</th>\n",
       "      <th>exclam_text</th>\n",
       "      <th>...</th>\n",
       "      <th>text_ngram_worker</th>\n",
       "      <th>text_ngram_working</th>\n",
       "      <th>text_ngram_world</th>\n",
       "      <th>text_ngram_would</th>\n",
       "      <th>text_ngram_wrong</th>\n",
       "      <th>text_ngram_wrote</th>\n",
       "      <th>text_ngram_year</th>\n",
       "      <th>text_ngram_yet</th>\n",
       "      <th>text_ngram_york</th>\n",
       "      <th>text_ngram_young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>495</td>\n",
       "      <td>12</td>\n",
       "      <td>4.804040</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042374</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "      <td>8</td>\n",
       "      <td>5.213115</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.075998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174931</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>15</td>\n",
       "      <td>5.168966</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>14</td>\n",
       "      <td>5.180180</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>11</td>\n",
       "      <td>4.554762</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.065641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  text_wc  title_wc  av_word_len_text  av_word_len_title  \\\n",
       "0      1      495        12          4.804040           5.583333   \n",
       "1      1      305         8          5.213115           7.625000   \n",
       "2      1      580        15          5.168966           5.000000   \n",
       "3      1      444        14          5.180180           4.571429   \n",
       "4      1      420        11          4.554762           5.363636   \n",
       "\n",
       "   upper_text_wc  upper_title_wc  numerics_text  numerics_title  exclam_text  \\\n",
       "0              5               0              4               0            6   \n",
       "1              3               0              0               0            0   \n",
       "2             42               0              0               0            2   \n",
       "3              5               1              5               0            0   \n",
       "4              0               0              0               0            0   \n",
       "\n",
       "   ...  text_ngram_worker  text_ngram_working  text_ngram_world  \\\n",
       "0  ...                0.0             0.00000          0.000000   \n",
       "1  ...                0.0             0.00000          0.075998   \n",
       "2  ...                0.0             0.00000          0.000000   \n",
       "3  ...                0.0             0.05844          0.000000   \n",
       "4  ...                0.0             0.00000          0.065641   \n",
       "\n",
       "   text_ngram_would  text_ngram_wrong  text_ngram_wrote  text_ngram_year  \\\n",
       "0          0.042374          0.051551               0.0         0.397070   \n",
       "1          0.000000          0.000000               0.0         0.000000   \n",
       "2          0.000000          0.000000               0.0         0.000000   \n",
       "3          0.087214          0.000000               0.0         0.034052   \n",
       "4          0.000000          0.000000               0.0         0.000000   \n",
       "\n",
       "   text_ngram_yet  text_ngram_york  text_ngram_young  \n",
       "0        0.000000         0.000000          0.000000  \n",
       "1        0.000000         0.174931          0.000000  \n",
       "2        0.000000         0.000000          0.000000  \n",
       "3        0.000000         0.000000          0.000000  \n",
       "4        0.076686         0.000000          0.092756  \n",
       "\n",
       "[5 rows x 1017 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features and label\n",
    "X = df.drop('label', axis=1)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#split data into 75% training set and 25% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11793184280395508"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize model\n",
    "mnb = MultinomialNB()\n",
    "#fit model to training data and caclulate training time\n",
    "t1 = time.time()\n",
    "mnb.fit(X_train,y_train)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436374795417348"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "mnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      5304\n",
      "           1       0.93      0.94      0.94      4472\n",
      "\n",
      "    accuracy                           0.94      9776\n",
      "   macro avg       0.94      0.94      0.94      9776\n",
      "weighted avg       0.94      0.94      0.94      9776\n",
      "\n",
      "[[5006  298]\n",
      " [ 260 4212]]\n"
     ]
    }
   ],
   "source": [
    "#make predictions on test set\n",
    "mnb_preds = mnb.predict(X_test)\n",
    "#testing metrics\n",
    "print(classification_report(y_test, mnb_preds))\n",
    "print(confusion_matrix(y_test, mnb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split unscaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.69265604019165"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize model\n",
    "rfc = RandomForestClassifier()\n",
    "#fit model to training data and caclulate training time\n",
    "t1 = time.time()\n",
    "rfc.fit(X_train, y_train)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5304\n",
      "           1       0.99      0.99      0.99      4472\n",
      "\n",
      "    accuracy                           0.99      9776\n",
      "   macro avg       0.99      0.99      0.99      9776\n",
      "weighted avg       0.99      0.99      0.99      9776\n",
      "\n",
      "[[5279   25]\n",
      " [  39 4433]]\n"
     ]
    }
   ],
   "source": [
    "#make predictions on test set\n",
    "rfc_preds = rfc.predict(X_test)\n",
    "#testing metrics\n",
    "print(classification_report(y_test, rfc_preds))\n",
    "print(confusion_matrix(y_test, rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=False,\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [2, 5, 10, None],\n",
       "                                        'n_estimators': [10, 50, 100, 150,\n",
       "                                                         200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tune hyperparameters with RandomizedSearchCV\n",
    "params = {'n_estimators':[10,50,100,150,200], 'criterion': ['gini', 'entropy'], 'max_depth':[2,5,10, None]}\n",
    "rf_cv = RandomizedSearchCV(RandomForestClassifier(), param_distributions=params, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.998176</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth param_criterion  mean_test_score  \\\n",
       "0                200            None            gini         0.999681   \n",
       "3                 50            None            gini         0.999469   \n",
       "5                100              10            gini         0.999219   \n",
       "4                150               5            gini         0.998325   \n",
       "8                100               5         entropy         0.998176   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "3                2  \n",
       "5                3  \n",
       "4                4  \n",
       "8                5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make dataframe of random search results\n",
    "rf_cv_results = pd.DataFrame(rf_cv.cv_results_)\n",
    "rf_cv_results[['param_n_estimators', 'param_max_depth', 'param_criterion', 'mean_test_score', 'rank_test_score']].sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'max_depth': None, 'criterion': 'gini'}\n",
      "0.9996807526079238\n"
     ]
    }
   ],
   "source": [
    "#find best parameters\n",
    "print(rf_cv.best_params_)\n",
    "print(rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5304\n",
      "           1       0.99      0.99      0.99      4472\n",
      "\n",
      "    accuracy                           0.99      9776\n",
      "   macro avg       0.99      0.99      0.99      9776\n",
      "weighted avg       0.99      0.99      0.99      9776\n",
      "\n",
      "[[5275   29]\n",
      " [  38 4434]]\n"
     ]
    }
   ],
   "source": [
    "#build a second random forest model with the best parameters\n",
    "rfc2 = RandomForestClassifier(**rf_cv.best_params_)\n",
    "rfc2.fit(X_train, y_train)\n",
    "rfc2_preds = rfc2.predict(X_test)\n",
    "#test metrics\n",
    "print(classification_report(y_test, rfc2_preds))\n",
    "print(confusion_matrix(y_test, rfc2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>upper_title_wc</th>\n",
       "      <td>0.097296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_said</th>\n",
       "      <td>0.079227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_wc</th>\n",
       "      <td>0.074212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_image</th>\n",
       "      <td>0.061524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qmark_text</th>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_ngram_video</th>\n",
       "      <td>0.033167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_p</th>\n",
       "      <td>0.030983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at_sign</th>\n",
       "      <td>0.025130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclam_text</th>\n",
       "      <td>0.015843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_word_len_text</th>\n",
       "      <td>0.014964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_president donald</th>\n",
       "      <td>0.014694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep_Dec</th>\n",
       "      <td>0.014417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_even</th>\n",
       "      <td>0.012552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_like</th>\n",
       "      <td>0.012330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclam_title</th>\n",
       "      <td>0.011810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_fact</th>\n",
       "      <td>0.010894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_minister</th>\n",
       "      <td>0.010796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_wc</th>\n",
       "      <td>0.009216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_know</th>\n",
       "      <td>0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_video</th>\n",
       "      <td>0.007289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             importance\n",
       "upper_title_wc                 0.097296\n",
       "text_ngram_said                0.079227\n",
       "title_wc                       0.074212\n",
       "text_ngram_image               0.061524\n",
       "qmark_text                     0.035558\n",
       "title_ngram_video              0.033167\n",
       "stop_p                         0.030983\n",
       "at_sign                        0.025130\n",
       "exclam_text                    0.015843\n",
       "av_word_len_text               0.014964\n",
       "text_ngram_president donald    0.014694\n",
       "Sep_Dec                        0.014417\n",
       "text_ngram_even                0.012552\n",
       "text_ngram_like                0.012330\n",
       "exclam_title                   0.011810\n",
       "text_ngram_fact                0.010894\n",
       "text_ngram_minister            0.010796\n",
       "text_wc                        0.009216\n",
       "text_ngram_know                0.008704\n",
       "text_ngram_video               0.007289"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dataframe of the top 20 most important features in the model\n",
    "pd.DataFrame(rfc2.feature_importances_, index=df.drop('label', axis=1).columns, columns=['importance']).sort_values(by='importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale and split data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4320287704467773"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initizlize and train model\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "t1 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5304\n",
      "           1       0.99      0.98      0.99      4472\n",
      "\n",
      "    accuracy                           0.99      9776\n",
      "   macro avg       0.99      0.99      0.99      9776\n",
      "weighted avg       0.99      0.99      0.99      9776\n",
      "\n",
      "[[5252   52]\n",
      " [  70 4402]]\n"
     ]
    }
   ],
   "source": [
    "#make prediction and calculate testing metrics\n",
    "lr_preds = lr.predict(X_test)\n",
    "print(classification_report(y_test, lr_preds))\n",
    "print(confusion_matrix(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=None,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                                        'solver': ['lbfgs', 'sag', 'saga']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune model with RandomizedSearchCV\n",
    "params = {'penalty':['l1', 'l2', 'elasticnet'], 'C':np.logspace(-2,2,5), 'solver':['lbfgs', 'sag', 'saga']}\n",
    "lr_cv = RandomizedSearchCV(LogisticRegression(), param_distributions=params, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "lr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999135</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sag</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saga</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sag</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_solver param_penalty param_C  mean_test_score  rank_test_score\n",
       "5        lbfgs            l2    0.01         0.999211                1\n",
       "4          sag            l2    0.01         0.999210                2\n",
       "9         saga            l2    0.01         0.999207                3\n",
       "8         saga            l1      10         0.999141                4\n",
       "1         saga            l2      10         0.999135                5\n",
       "0        lbfgs            l1     100              NaN                6\n",
       "2          sag    elasticnet      10              NaN                7\n",
       "3         saga    elasticnet    0.01              NaN                8\n",
       "6        lbfgs    elasticnet      10              NaN                9\n",
       "7          sag            l1    0.01              NaN               10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a dataframe of search results sorted by best score\n",
    "lr_cv_results = pd.DataFrame(lr_cv.cv_results_)\n",
    "lr_cv_results[['param_solver', 'param_penalty', 'param_C', 'mean_test_score', 'rank_test_score']].sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992112152421515\n",
      "{'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#find best score and best parameters\n",
    "print(lr_cv.best_score_)\n",
    "print(lr_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a 2nd logisitic regression model with best parameters\n",
    "lr2 = LogisticRegression(**lr_cv.best_params_, max_iter=200)\n",
    "lr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5304\n",
      "           1       0.99      0.99      0.99      4472\n",
      "\n",
      "    accuracy                           0.99      9776\n",
      "   macro avg       0.99      0.99      0.99      9776\n",
      "weighted avg       0.99      0.99      0.99      9776\n",
      "\n",
      "[[5272   32]\n",
      " [  59 4413]]\n"
     ]
    }
   ],
   "source": [
    "#make predictions and calculate metrics\n",
    "lr2_preds = lr2.predict(X_test)\n",
    "print(classification_report(y_test, lr2_preds))\n",
    "print(confusion_matrix(y_test, lr2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>upper_title_wc</th>\n",
       "      <td>1.255792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_wc</th>\n",
       "      <td>1.007022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_image</th>\n",
       "      <td>0.683703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_ngram_video</th>\n",
       "      <td>0.520196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_ngram_breaking</th>\n",
       "      <td>0.375867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclam_title</th>\n",
       "      <td>0.368532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_gop</th>\n",
       "      <td>0.365698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_even</th>\n",
       "      <td>0.258577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_ngram_president trump</th>\n",
       "      <td>0.230691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at_sign</th>\n",
       "      <td>0.230040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                coef\n",
       "upper_title_wc              1.255792\n",
       "title_wc                    1.007022\n",
       "text_ngram_image            0.683703\n",
       "title_ngram_video           0.520196\n",
       "title_ngram_breaking        0.375867\n",
       "exclam_title                0.368532\n",
       "text_ngram_gop              0.365698\n",
       "text_ngram_even             0.258577\n",
       "text_ngram_president trump  0.230691\n",
       "at_sign                     0.230040"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe of model coefficients to find most important features\n",
    "pd.DataFrame(lr2.coef_.T, index=df.drop('label', axis=1).columns, columns=['coef']).sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687.2539291381836"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize, fit, and time model\n",
    "svc = SVC()\n",
    "t1 = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990793780687398"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5304\n",
      "           1       0.99      0.99      0.99      4472\n",
      "\n",
      "    accuracy                           0.99      9776\n",
      "   macro avg       0.99      0.99      0.99      9776\n",
      "weighted avg       0.99      0.99      0.99      9776\n",
      "\n",
      "[[5277   27]\n",
      " [  51 4421]]\n"
     ]
    }
   ],
   "source": [
    "#make predictions and calculate metrics\n",
    "svc_preds = svc.predict(X_test)\n",
    "print(classification_report(y_test, svc_preds))\n",
    "print(confusion_matrix(y_test, svc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.049558639526367"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize, fit, and time model\n",
    "knn = KNeighborsClassifier()\n",
    "t1=time.time()\n",
    "knn.fit(X_train, y_train)\n",
    "t2 = time.time() - t1\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7208128750681942"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training accuracy\n",
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.43      0.60      5304\n",
      "           1       0.59      0.97      0.74      4472\n",
      "\n",
      "    accuracy                           0.68      9776\n",
      "   macro avg       0.77      0.70      0.67      9776\n",
      "weighted avg       0.79      0.68      0.66      9776\n",
      "\n",
      "[[2306 2998]\n",
      " [ 123 4349]]\n"
     ]
    }
   ],
   "source": [
    "#make predictions and calculate metrics\n",
    "knn_preds=knn.predict(X_test)\n",
    "print(classification_report(y_test, knn_preds))\n",
    "print(confusion_matrix(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best model\n",
    "filename = 'rf_model.sav'\n",
    "pickle.dump(rfc2, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
